{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#primary requirements: # python3, numpy, pandas, xarray, dask, bottleneck, netCDF4, cftime, matplotlib\n",
    "# run this script to check if all dependencies are installed and working\n",
    "# also fixes np.NaN to np.nan in marineHeatWaves module\n",
    "\n",
    "import sys, platform\n",
    "import numpy as np\n",
    "import pandas as pd, xarray as xr, dask, bottleneck, netCDF4, cftime, matplotlib\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple, Dict, Union\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.dates as mdates\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "from glob import glob\n",
    "\n",
    "# convert np.NAN to np.nan to avoid dependency issues\n",
    "if not hasattr(np, \"NaN\"):\n",
    "    np.NaN = np.nan  \n",
    "\n",
    "print(sys.executable)\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb328cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create daily mean files data from 3-hourly ERA5 wind data\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask\n",
    "\n",
    "# set the file paths\n",
    "# input 3-hourly files path\n",
    "SRC_GLOB = \"/home/Desktop/ERA5_wind_data_30S_30N_20E_110E/era5_wind_*.nc\"\n",
    "# output daily mean files path\n",
    "OUT_DIR  = Path(\"/home/Desktop/Jupyter files/outputs/wind/daily\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tname = \"valid_time\"     # file has 'valid_time' variable instead of 'time'\n",
    "# variable name\n",
    "u_name, v_name = \"u10\", \"v10\"\n",
    "\n",
    "# set the data size and chunking for output files (adjust as needed)\n",
    "ENC = {\n",
    "    u_name: {\"zlib\": True, \"complevel\": 4, \"dtype\": \"float32\", \"chunksizes\": (90, 120, 120)},\n",
    "    v_name: {\"zlib\": True, \"complevel\": 4, \"dtype\": \"float32\", \"chunksizes\": (90, 120, 120)},\n",
    "}\n",
    "\n",
    "dask.config.set(**{\"array.slicing.split_large_chunks\": True})\n",
    "\n",
    "# open file files from path\n",
    "def year_from_path(p: str):\n",
    "    m = re.search(r\"(19|20)\\d{4}|(19|20)\\d{2}\", p)  \n",
    "    \"\"\" Prefer pure 4-digit year; fallback if filenames have YYYYMM\"\"\"\n",
    "    m4 = re.search(r\"(19|20)\\d{2}\", p)\n",
    "    return int(m4.group(0)) if m4 else None\n",
    "\n",
    "def open_year(paths):\n",
    "    \"\"\"Keep each file as one contiguous chunk along time\"\"\"\n",
    "    \n",
    "    return xr.open_mfdataset(paths,combine=\"by_coords\",engine=\"netcdf4\",chunks={tname: -1},parallel=False,lock=False, decode_times=True,\n",
    "                             drop_variables=None,)[[u_name, v_name]]\n",
    "\n",
    "# collect files by year\n",
    "paths = sorted(glob(SRC_GLOB))\n",
    "by_year = {}\n",
    "for p in paths:\n",
    "    y = year_from_path(p)\n",
    "    if y is not None:\n",
    "        by_year.setdefault(y, []).append(p)\n",
    "\n",
    "years = [y for y in sorted(by_year) if 1982 <= y <= 2024]\n",
    "print(f\"Found years: {years[0]}–{years[-1]} ({len(years)} years)\")\n",
    "\n",
    "# convert file per year \n",
    "for y in years:\n",
    "    out_nc = OUT_DIR / f\"era5_wind_daily_{y}.nc\"\n",
    "    if out_nc.exists():\n",
    "        print(f\"Skip file if {out_nc.name} already exists.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"[{y}] opening {len(by_year[y])} file(s)…\")\n",
    "    ds3h = open_year(by_year[y])\n",
    "\n",
    "    # daily mean file for having u10 and v10 variables\n",
    "    daily = (ds3h.resample({tname: \"1D\"}).mean().astype(\"float32\") .sortby(tname))\n",
    "\n",
    "    # keep the file year same as input data\n",
    "    daily = daily.sel({tname: slice(f\"{y}-01-01\", f\"{y}-12-31\")})\n",
    "\n",
    "    # write NetCDF\n",
    "    print(f\"[{y}] writing {out_nc.name} …\")\n",
    "    daily.to_netcdf(out_nc, format=\"NETCDF4\", engine=\"netcdf4\", encoding=ENC)\n",
    "\n",
    "    # print sample stats\n",
    "    tt = pd.to_datetime(daily[tname].values)\n",
    "    print(f\"[{y}] saved {tt.size} daily steps; {tt[0].date()} → {tt[-1].date()}\")\n",
    "\n",
    "print(\"✓ Done. Daily files are saving in:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf8878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open metadata and check the files structure and values after daily menaning and conversion to check if the files are correct and ready for analysis\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "from glob import glob\n",
    "\n",
    "FILES_GLOB = \"/home/Desktop/ERA5 wind data/ERA5_daily_wind_data_30S_30N_20E_110E/era5_wind_daily_*.nc\"\n",
    "\n",
    "# open files path \n",
    "ds = xr.open_mfdataset(sorted(glob(FILES_GLOB)),combine=\"by_coords\",engine=\"netcdf4\",chunks={\"valid_time\": 1752})  \n",
    "\n",
    "# Names\n",
    "tname = \"time\" if \"time\" in ds.dims else \"valid_time\"\n",
    "latn  = \"lat\" if \"lat\" in ds.coords else \"latitude\"\n",
    "lonn  = \"lon\" if \"lon\" in ds.coords else \"longitude\"\n",
    "u_name = \"u10\"; v_name = \"v10\"\n",
    "print(f\"Detected wind variables: u='{u_name}', v='{v_name}' (10 m)\")\n",
    "\n",
    "# coordinates & coverage\n",
    "print(\"\\n1st three cordinated \")\n",
    "def _preview(arr):\n",
    "    vals = arr.values\n",
    "    if vals.ndim == 0:\n",
    "        return f\"{vals!r} (scalar)\"\n",
    "    return f\"{vals[:3]} ... {vals[-3:]}\"\n",
    "for c in [tname, latn, lonn]:\n",
    "    print(f\"{c:>10s}: {_preview(ds[c])}\")\n",
    "if \"expver\" in ds.coords:\n",
    "    print(f\"{'expver':>10s}: {_preview(ds['expver'])}\")\n",
    "\n",
    "# print dimentions\n",
    "print(\"\\nDimensions:\")\n",
    "for k, v in ds.sizes.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# set the variable attributes & chunking data\n",
    "def show_var(name):\n",
    "    da = ds[name]\n",
    "    print(f\"\\nVariable '{name}' attrs\")\n",
    "    for k, v in da.attrs.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    if hasattr(da.data, \"chunks\") and da.data.chunks:\n",
    "        print(\"chunks:\", da.data.chunks)\n",
    "\n",
    "show_var(u_name)\n",
    "show_var(v_name)\n",
    "\n",
    "# quick check of time coverage & values \n",
    "t = pd.to_datetime(ds[tname].values)\n",
    "t0, t1 = t[0], t[-1]\n",
    "print(f\"\\n=== Time Coverage ===\\nStart: {t0}  End: {t1}  Length: {t.size} steps\")\n",
    "\n",
    "# compute quick spatial means for the first and last day to check values\n",
    "u, v = ds[u_name], ds[v_name]\n",
    "first_day = slice(str(pd.to_datetime(t0).date()), str(pd.to_datetime(t0).date()))\n",
    "last_day  = slice(str(pd.to_datetime(t1).date()), str(pd.to_datetime(t1).date()))\n",
    "\n",
    "u_first = u.sel({tname: first_day}).mean([tname, latn, lonn]).compute().item()\n",
    "v_first = v.sel({tname: first_day}).mean([tname, latn, lonn]).compute().item()\n",
    "u_last  = u.sel({tname: last_day}).mean([tname, latn, lonn]).compute().item()\n",
    "v_last  = v.sel({tname: last_day}).mean([tname, latn, lonn]).compute().item()\n",
    "print(f\"\\nsample spatial velocities plotting u10 and v10 in m/s\\n\"\n",
    "      f\"{str(t0.date())}: u={u_first:.2f}, v={v_first:.2f}\\n\"\n",
    "      f\"{str(t1.date())}: u={u_last:.2f},  v={v_last:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad0e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation for zarr file computation and quick access for analysis of the daily mean wind data\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "# file path for the daily mean wind data\n",
    "FILES_GLOB = \"/home/Desktop/ERA5 wind data/ERA5_daily_wind_data_30S_30N_20E_110E/era5_wind_daily_*.nc\"\n",
    "\n",
    "# North Indian Ocean ROI\n",
    "ROI = dict(lat_min=0.0, lat_max=30.0, lon_min=40.0, lon_max=110.0)\n",
    "\n",
    "# Quiver subsampling for readability, increase or decrease if arrows are too dense or less desnse\n",
    "QUIVER_STEP = 6  \n",
    "\n",
    "# open files path and load data\n",
    "ds = xr.open_mfdataset(sorted(glob(FILES_GLOB)),combine=\"by_coords\", engine=\"netcdf4\",chunks={\"valid_time\": 365}  )\n",
    "\n",
    "# find the standard lat, lon and valiriable names\n",
    "tname = \"time\" if \"time\" in ds.dims else \"valid_time\"\n",
    "latn  = \"lat\" if \"lat\" in ds.coords else \"latitude\"\n",
    "lonn  = \"lon\" if \"lon\" in ds.coords else \"longitude\"\n",
    "u_name, v_name = \"u10\", \"v10\"\n",
    "\n",
    "# Slice ROI (handle descending latitude if present)\n",
    "def slice_roi(ds, roi):\n",
    "    lat = ds[latn]\n",
    "    lon = ds[lonn]\n",
    "    lat_slice = slice(roi[\"lat_min\"], roi[\"lat_max\"]) if lat[0] < lat[-1] else slice(roi[\"lat_max\"], roi[\"lat_min\"])\n",
    "    lon_slice = slice(roi[\"lon_min\"], roi[\"lon_max\"]) if lon[0] < lon[-1] else slice(roi[\"lon_max\"], roi[\"lon_min\"])\n",
    "    return ds.sel({latn: lat_slice, lonn: lon_slice})\n",
    "\n",
    "ds_roi = slice_roi(ds[[u_name, v_name]], ROI)\n",
    "ds_roi = ds_roi.chunk({tname: 365, latn: 80, lonn: 80})\n",
    "\n",
    "print(ds_roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the daily zarr file for quick access and analysis of the daily mean wind data\n",
    "from pathlib import Path\n",
    "\n",
    "# Compute daily resultant magnitude of u10 and v10\n",
    "ubar = ds_roi[u_name]\n",
    "vbar = ds_roi[v_name]\n",
    "speed = np.hypot(ubar, vbar)\n",
    "daily_vec = xr.Dataset(\n",
    "    data_vars=dict(ubar=ubar, vbar=vbar, speed=speed),\n",
    "    coords={tname: ds_roi[tname], latn: ds_roi[latn], lonn: ds_roi[lonn]},\n",
    "    attrs=dict(note=\"Daily mean 10m winds, ROI subset 0–30N, 40–110E; ubar/vbar are daily mean components; speed=hypot(ubar,vbar).\")\n",
    ")\n",
    "\n",
    "# save zarr file path  \n",
    "ROI_ZARR = \"/home/Desktop/Jupyter files/outputs/wind/era5_u10_v10_daily_1982_2024_NIO_ROI.zarr\"\n",
    "# overwrite safely\n",
    "if Path(ROI_ZARR).exists():\n",
    "    import shutil, os\n",
    "    shutil.rmtree(ROI_ZARR)\n",
    "daily_vec.to_zarr(ROI_ZARR, mode=\"w\")\n",
    "print(f\"Saved zarr file to:\\n  {ROI_ZARR}\\n\", daily_vec)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
